{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <h1>MDP RESOLUTION FOR THE RADIO RESOURCE ALLOCATION PROBLEM</h1>\n",
    "\n",
    "<ul>\n",
    "    <li><a href=\"routines definition\">The Routines Definition</a> section should be ran first for initialization.</li>\n",
    "    <li><a href=\"Tests\">The Tests</a> section is for verifying the various modules.</li>\n",
    "    <li><a href=\"Simulations\">The Simulations</a> section is to compare the abstraction models and try the selected one.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 id=\"routines definition\">ROUTINES DEFINITION</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import csv\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from itertools import product\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from scipy.stats import poisson\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"CUDA is AVAILABLE\" if torch.cuda.is_available() else \"cuda is NOT available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "def soft_shift_poisson(rate:int, left_shift:int=0) -> float:\n",
    "    \"\"\"\n",
    "    Returns the mathematical expectation of max(0,X-left_shift), where X a Poisson distribution.\n",
    "\n",
    "    Args:\n",
    "        rate (int).\n",
    "        left_shift (int, optional). Defaults to 0.\n",
    "    \"\"\"\n",
    "    if left_shift == 0: return rate\n",
    "    sub_probability = poisson.cdf(2*left_shift-1,rate)\n",
    "    sub_mean =  0\n",
    "    for n in range(2*left_shift): sub_mean += n*poisson.pmf(n,rate)\n",
    "    remaining_mean = rate - sub_mean\n",
    "    remaining_probability = 1 - sub_probability\n",
    "    return remaining_mean - remaining_probability*left_shift\n",
    "\n",
    "def small_MDP_solution(num_states:int, num_actions:int, transition_matrix:torch.tensor, cost_matrix:torch.tensor, discount_factor:float=0.9, precision:float=1e-16) -> torch.tensor:\n",
    "    \"\"\"Solution of an MDP (S, A, T, C) with small state and action spaces.\n",
    "\n",
    "    Args:\n",
    "        num_states (int): Number of states. Assume S = {0, ..., num_states-1}.\n",
    "        num_actions (int): Number of actions. Assume A = {0, ..., num_actions-1}.\n",
    "        transition_matrix (torch.tensor): Tensor representing the transition matrix T. Assume T[a,s,s'] is the probability that the system transitions to state s' when action a was taken in state s.\n",
    "        cost_matrix (torch.tensor): Tensor representing the cost matrix C. Assume C[a,s] is the expected cost for taking action a in state s.\n",
    "        discount_factor (float, optional). Defaults to 0.9.\n",
    "        precision (float, optional): Upper bound of the distance (in norm \\infty) between the optimal value function and the computed value function. Defaults to 1e-16.\n",
    "\n",
    "    Returns:\n",
    "        torch.tensor: (2, num_states) matrix. Each column corresponds to a state. The first line is the action suggested, the second line is the value estimated.\n",
    "    \"\"\"\n",
    "    precision = torch.tensor([precision],dtype=float).to(device).item()\n",
    "    transition_matrix, cost_matrix = transition_matrix.to(device).to(float), cost_matrix.to(device)\n",
    "    discount_factor = torch.tensor([discount_factor],dtype=float).to(device)\n",
    "    error_factor = discount_factor / (one-discount_factor)\n",
    "    states_vector = torch.tensor(range(num_states),dtype=int).to(device)\n",
    "    actions_vector = torch.tensor(range(num_actions),dtype=int).to(device)\n",
    "    old_value, new_value = torch.zeros([num_states],dtype=float).to(device), torch.zeros([num_states],dtype=float).to(device)\n",
    "    error = \"#NA\"\n",
    "    policy = torch.zeros([num_states],dtype=int).to(device)\n",
    "    while True:\n",
    "        for s in states_vector:\n",
    "            s_p = s.item() \n",
    "            print(f\"Resolution of the small MDP.   Current error = {error};  current state number = {s_p}\", end=\"\\r\")\n",
    "            Q = torch.zeros([num_actions],dtype=float).to(device)\n",
    "            for a in actions_vector: Q[a] = cost_matrix[a,s] + discount_factor*torch.dot(transition_matrix[a,s],old_value)\n",
    "            new_value[s] = torch.min(Q)\n",
    "            policy[s] = torch.argmin(Q)\n",
    "        diff_max, diff_min = torch.max(new_value - old_value), torch.min(new_value - old_value)\n",
    "        diff_scope = diff_max - diff_min\n",
    "        error = (error_factor * diff_scope).item()\n",
    "        # error = torch.max(torch.abs(new_value-old_value))\n",
    "        if error <= precision: break\n",
    "        old_value = new_value.clone()\n",
    "    print(\" \"*150, end=\"\\r\")\n",
    "    return torch.stack([policy, new_value])\n",
    "\n",
    "# Place the more usual numbers on the device.\n",
    "two = torch.tensor([2],dtype=float).to(device)\n",
    "one = torch.tensor([1],dtype=float).to(device)\n",
    "zero = torch.tensor([0],dtype=float).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class ground_model:\n",
    "    \"\"\"\n",
    "    Definition and operations for a radio resource allocation problem.\n",
    "    Parameters:\n",
    "    max_size = maximum number of bits in an user equipment's queue;\n",
    "    number of user equipments; number of resource blocks;\n",
    "    arrival_rates_set_to_default: indicate if the arrival rate at each user equipment's buffer is set to default\n",
    "    CQIs_are_equal: indicates if the chanel quality index is constant in the UE and in the RB;\n",
    "    CQI_base = number of bits scheduled for transmission when CQI=1;\n",
    "    coef_of_drop, coef_of_latency, power_of_drop, power_of_latency = α, β, x, y:\n",
    "    cost = α*(cost for rejection)**x + β(cost for latency)**y;\n",
    "    discount factor;\n",
    "    precision = bound of the difference between the calculated and the optimal value function of the MDP;\n",
    "    path = location of the results of the operations (if it is not indicated from the root, the location is in the current directory).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_size:int=3, number_UEs:int=6, number_RBs:int=2, \n",
    "                 arrival_rates_set_to_default=None,\n",
    "                 CQIs_are_equal=True, CQI_base:float=1,\n",
    "                 coef_of_drop:float=1, coef_of_latency:float=1, power_of_drop:float=1, power_of_latency:float=1, \n",
    "                 discount_factor:float=0.9, precision:float=1e-16,\n",
    "                 path=None) -> None:\n",
    "        \n",
    "        # States and actions\n",
    "        number_states, number_actions = (max_size + 1) ** number_UEs, number_UEs ** number_RBs\n",
    "        range_UE_indices = torch.tensor(range(number_UEs))\n",
    "        range_number_bits = torch.tensor(range(max_size+1))\n",
    "        list_states = list(product(range_number_bits,repeat=number_UEs))\n",
    "        list_actions = list(product(range_UE_indices, repeat=number_RBs))\n",
    "        \n",
    "        # Send to the device: the data, the ranges for indices, the states and the actions\n",
    "        self.max_size = torch.tensor([max_size],dtype=int).to(device)\n",
    "        self.number_UEs, self.number_RBs = torch.tensor([number_UEs],dtype=int).to(device), torch.tensor([number_RBs],dtype=int).to(device)\n",
    "        self.coef_of_drop, self.coef_of_latency = torch.tensor([coef_of_drop],dtype=float).to(device), torch.tensor([coef_of_latency],dtype=float).to(device)\n",
    "        self.power_of_drop, self.power_of_latency = torch.tensor([power_of_drop],dtype=float).to(device), torch.tensor([power_of_latency],dtype=float).to(device)\n",
    "        self.discount_factor, self.precision = torch.tensor([discount_factor], dtype=float).to(device), torch.tensor([precision], dtype=float).to(device)\n",
    "        self.number_states, self.number_actions = torch.tensor([number_states]).to(device), torch.tensor([number_actions]).to(device)\n",
    "        self.range_UE_indices, self.range_RB_indices = torch.tensor(range(number_UEs)).to(device), torch.tensor(range(number_RBs)).to(device)\n",
    "        self.range_state_indices, self.range_action_indices = torch.tensor(range(number_states)).to(device), torch.tensor(range(number_actions)).to(device)\n",
    "        self.states_matrix, self.actions_matrix = torch.tensor(list_states).to(device), torch.tensor(list_actions).to(device)\n",
    "        self.empty_buffer = torch.zeros([self.number_UEs],dtype=int).to(device)                      # Number of bits in each UE's empty buffer\n",
    "        self.full_buffer = self.max_size*torch.ones([self.number_UEs],dtype=int).to(device)          # Number of bits in each UE's full buffer\n",
    "        \n",
    "        # Get the arrival rates\n",
    "        if arrival_rates_set_to_default:\n",
    "            arrival_rates_vector = torch.ones([self.number_UEs]).to(device)\n",
    "            fraction = torch.tensor([max_size/3],dtype=float).to(device)\n",
    "            print(f\"Arrival rate is set to default for each UE: lambda = {fraction.item()}\")\n",
    "            arrival_rates_vector = fraction*arrival_rates_vector\n",
    "        else:\n",
    "            arrival_rates_vector = torch.ones([self.number_UEs]).to(device)\n",
    "            print(\"Setting the arrival rate for each UE.\")\n",
    "            decision = input(\"Same arrival rate? (y/n)\")\n",
    "            if \"Y\" in decision.upper():\n",
    "                value_ = float(input(\"For all UE, arrival rate is: \"))\n",
    "                value_ = torch.tensor([value_],dtype=float).to(device)\n",
    "                arrival_rates_vector = value_*arrival_rates_vector\n",
    "            else:\n",
    "                for i in self.range_UE_indices:\n",
    "                    print(f\"Arrival rate for UE {i}: \")\n",
    "                    arrival_rates_vector[i] = float(input())\n",
    "        self.arrival_rates_vector = arrival_rates_vector\n",
    "        \n",
    "        # Get the chanel quality indices (CQIs) matrix\n",
    "        if CQIs_are_equal:\n",
    "            self.CQI_matrix = CQI_base*torch.ones([self.number_UEs,number_RBs],dtype=float).to(device)\n",
    "        else:\n",
    "            self.CQI_matrix = torch.ones([self.number_UEs,number_RBs],dtype=float).to(device)\n",
    "            print(\"Definition of the chanel quality indices.\")\n",
    "            decision = input(\"Allow various values of CQI? (y/n): \")\n",
    "            if \"Y\" in decision.upper():\n",
    "                print(\"\\nFor each UE and each RB, let's define the CQI as:  CQI = (coef of UE and RB)*(common base)\")\n",
    "                print(\"Enter all the coefficients. Later on, you will enter the common base to multiply.\")\n",
    "                for i,j in product(self.range_UE_indices,self.range_RB_indices):\n",
    "                    print(f\"    Coefficient for UE {i} and RB {j}: \", end=\"\")\n",
    "                    time.sleep(0.4)\n",
    "                    value_ = input()\n",
    "                    if value_.isnumeric(): \n",
    "                        print(value_)\n",
    "                        value_ = torch.tensor([float(value_)],dtype=float).to(device)\n",
    "                        self.CQI_matrix[i,j] = value_\n",
    "                value_ = input(\"Enter the common base: \")\n",
    "                if value_.isnumeric(): \n",
    "                    value_ = torch.tensor([float(value_)],dtype=float).to(device)\n",
    "                    CQI_base = value_\n",
    "                self.CQI_matrix = CQI_base*self.CQI_matrix\n",
    "                # self.CQI_matrix = self.CQI_matrix.to(device)\n",
    "                \n",
    "        # Prepare the resolution\n",
    "        self.prepare_resolution()\n",
    "        \n",
    "    def prepare_resolution(self, directory_root=None, solution=None, from_scratch = True):\n",
    "        \n",
    "        # Prepare the path for the solution and the simulations\n",
    "        if from_scratch:\n",
    "            if directory_root == None:\n",
    "                this_directory = os.getcwd()\n",
    "                solution_directory = \"Solution_for_B-\" + str(self.max_size.item()) + \"_UE-\" + str(self.number_UEs.item()) + \"_RB-\" + str(self.number_RBs.item())\n",
    "                directory_root = os.path.join(this_directory, solution_directory)\n",
    "            last_index = 1\n",
    "            while True:\n",
    "                directory = (directory_root if last_index==1 else directory_root + \"_\"+str(last_index))\n",
    "                if os.path.exists(directory):\n",
    "                    print(f\"Directory {directory} serves for the resolution.\")\n",
    "                    decision = input(\"Continue the last resolution in it? (Y/N): \")\n",
    "                    if \"Y\" in decision.upper(): break\n",
    "                    else:\n",
    "                        print(f\"This is, you should decide wether delete the existing resolution in {directory}\")\n",
    "                        print(\"and start a new resolution in this directory or let me look for another directory.\")\n",
    "                        decision = input(\"Start a new resolution in it? (Y/N): \")\n",
    "                        if \"Y\" in decision.upper():\n",
    "                            shutil.rmtree(directory)\n",
    "                            os.makedirs(directory)\n",
    "                            break\n",
    "                        else: last_index += 1\n",
    "                else:\n",
    "                    os.makedirs(directory)\n",
    "                    break\n",
    "            self.directory = directory\n",
    "        \n",
    "        # Prepare the initial value for the backup iteration and save it in a dedicated file\n",
    "        solution_path = os.path.join(self.directory, \"ground_solution.pth\")\n",
    "        if os.path.exists(solution_path):\n",
    "            if solution == None: self.solution = torch.load(solution_path).to(device)\n",
    "            else:\n",
    "                self.solution = solution\n",
    "                torch.save(self.solution, solution_path)\n",
    "        else:\n",
    "            self.solution = (torch.zeros([2,self.number_states],dtype=float).to(device) if solution==None else solution)\n",
    "            torch.save(self.solution, solution_path)\n",
    "        self.solution_path = solution_path\n",
    "        \n",
    "        # Prepare the file to store the error of running the backup iteration\n",
    "        self.error_path = error_path = os.path.join(self.directory, \"ground_error.txt\")\n",
    "        if os.path.exists(error_path):\n",
    "            with open(error_path, \"r\") as f:\n",
    "                error = f.read()\n",
    "                self.error = (float(error) if error.isnumeric() else \"#NA\")\n",
    "        else:\n",
    "            with open(error_path, \"w\") as f:\n",
    "                self.error = \"#NA\"\n",
    "                f.write(self.error)\n",
    "        \n",
    "    \n",
    "    def remainder_fn(self, state:torch.tensor, action:torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Returns the number of bits remaining in each UE's buffer if action of index action_index was taken in state of index state_index.\n",
    "        \"\"\"\n",
    "        state = state.to(device)\n",
    "        schedule = torch.zeros([self.number_UEs],dtype=float).to(device)  # Number of bits scheduled for transmission\n",
    "        for i,j in product(self.range_UE_indices,self.range_RB_indices): \n",
    "            if action[j]==i:\n",
    "                schedule[i] += self.CQI_matrix[i,j]\n",
    "        schedule = schedule.to(int)\n",
    "        angry_remainder = state - schedule    # Number of remaining bits if negative values are possible\n",
    "        return torch.max(self.empty_buffer, angry_remainder)\n",
    "    \n",
    "    def transition_probability_fn(self, state1:torch.tensor, action:torch.tensor, state2:torch.tensor) -> torch.tensor:\n",
    "        def UE_transition_probability_fn(rest:int, rate:float, next:int) -> torch.tensor:\n",
    "            max_size = self.max_size\n",
    "            sure, impossible = torch.tensor([1],dtype=float).to(device), torch.tensor([0],dtype=float).to(device)\n",
    "            if next<rest:     return impossible                                                           # next < rest\n",
    "            if next<max_size: return torch.tensor([poisson.pmf(next.item()-rest.item(),rate.item())],dtype=float).to(device)   # rest ≤ next < max_size  \n",
    "            range_next = torch.tensor(range((max_size-rest).item()),dtype=int).to(device)                 # next = max_size, then  P{size=next} = 1 - P{arrival<}\n",
    "            probability = sure\n",
    "            for arrival in range_next:\n",
    "                probability_arrival = torch.tensor([poisson.pmf(arrival.item(),rate.item())],dtype=float).to(device)\n",
    "                probability = probability - probability_arrival\n",
    "            return probability\n",
    "        rate = self.arrival_rates_vector\n",
    "        remainder = self.remainder_fn(state1,action)\n",
    "        probability = torch.tensor([1],dtype=float).to(device)\n",
    "        for i in self.range_UE_indices:                                                                    # i = queue index\n",
    "            probability = probability * UE_transition_probability_fn(remainder[i], rate[i], state2[i])\n",
    "        return probability\n",
    "    \n",
    "    def cost_fn(self, state:torch.tensor, action:torch.tensor) -> torch.tensor:\n",
    "        def exact_cost_fn(remainder:torch.tensor, state2:torch.tensor) -> torch.tensor:                     # Exact cost associated with the transition from state1 to state2\n",
    "            def partial_cost_fn(rest:torch.tensor, arrival:torch.tensor) -> torch.tensor:                   # Cost for transition of the queue\n",
    "                false_excess = arrival + rest - self.max_size\n",
    "                excess = torch.max(nothing, false_excess)\n",
    "                return self.coef_of_drop * excess**self.power_of_drop + self.coef_of_latency * rest**self.power_of_latency\n",
    "            \n",
    "            exact_cost = torch.tensor([0],dtype=float).to(device)\n",
    "            for q in self.range_UE_indices:\n",
    "                if state2[q] < remainder[q]:                                                                 # The transition is impossible\n",
    "                    exact_cost = torch.tensor([0],dtype=float).to(device)\n",
    "                    break\n",
    "                else:\n",
    "                    arrival = state2[q] - remainder[q]\n",
    "                    exact_cost = exact_cost + partial_cost_fn(remainder[q], arrival)\n",
    "            return exact_cost\n",
    "        \n",
    "        nothing = torch.tensor([0],dtype=int).to(device)\n",
    "        remainder = self.remainder_fn(state, action)\n",
    "        cost = torch.tensor([0],dtype=float).to(device)\n",
    "        for s in self.range_state_indices:\n",
    "            possible_state = self.states_matrix[s]\n",
    "            possible_exact_cost = exact_cost_fn(remainder, possible_state)\n",
    "            cost = cost + possible_exact_cost * self.transition_probability_fn(state,action,possible_state)\n",
    "        return cost\n",
    "    \n",
    "    def resolution(self, directory=None, solution=None, precision=None) -> torch.tensor:\n",
    "        \n",
    "        # Initialization\n",
    "        if directory == None: \n",
    "            directory = self.directory\n",
    "            from_scratch = False\n",
    "        else:\n",
    "            from_scratch = True\n",
    "        if precision == None: precision = self.precision\n",
    "        self.prepare_resolution(directory, solution, from_scratch)\n",
    "        \n",
    "        # Body of the resolution\n",
    "        gamma = self.discount_factor.item()\n",
    "        gamma_prime = gamma / (1-gamma)\n",
    "        old_value = self.solution[1].to(device)\n",
    "        new_value = self.solution[1].to(device)\n",
    "        current_policy, current_value = self.solution[0].to(device), self.solution[1].to(device)\n",
    "        policy = torch.zeros([self.number_states],dtype=int).to(device)\n",
    "        error = self.error\n",
    "        step = 0\n",
    "        try:\n",
    "            while True:\n",
    "                step += 1\n",
    "                for s in self.range_state_indices:\n",
    "                    print(f\"Ground model resolution.   Updating the value (step {step}).  Current error: {error};  current state: s_{s}\", end=\"\\r\")\n",
    "                    state1 = self.states_matrix[s]\n",
    "                    Q = torch.zeros([self.number_actions],dtype=float).to(device)\n",
    "                    for a in self.range_action_indices:\n",
    "                        action = self.actions_matrix[a]\n",
    "                        P = torch.zeros([self.number_states],dtype=float).to(device)\n",
    "                        for s2 in self.range_state_indices: \n",
    "                            state2 = self.states_matrix[s2]\n",
    "                            P[s2] = self.transition_probability_fn(state1, action, state2)\n",
    "                        Q[a] = self.cost_fn(state1,action) + self.discount_factor*torch.sum(old_value*P)\n",
    "                    new_value[s] = torch.min(Q)\n",
    "                    policy[s] = torch.argmin(Q)\n",
    "                current_policy, current_value = policy.clone(), new_value.clone()\n",
    "                diff = torch.abs(new_value - old_value)\n",
    "                max_diff = torch.max(diff).item() \n",
    "                error = gamma_prime * max_diff\n",
    "                if error <= precision: break\n",
    "        except KeyboardInterrupt:\n",
    "            pass \n",
    "        print(f\"Ground model resolution.   Updating the value (step {step}).  Current error: {error};  current state: s_{s}\", end=\"\\r\")\n",
    "        \n",
    "        # Storing the solution and the error\n",
    "        self.solution = torch.stack([current_policy, current_value])\n",
    "        torch.save(self.solution, self.solution_path)\n",
    "        with open(self.error_path, \"w\") as f:\n",
    "            f.write(str(error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "1"
    }
   },
   "outputs": [],
   "source": [
    "class abstract_model:\n",
    "    \"\"\"Make and solve an abstract model corresponding to a ground model\n",
    "\n",
    "    Args:\n",
    "        model (ground_model): the ground model on which the abstract model is built.\n",
    "        number_groups (int, optional): number of groups of UEs fo the abstract model. Defaults to 3.\n",
    "        coef_owners (str, optional): the object that receive a weight: \"UEs\" or \"groups\". Defaults to \"UEs\".\n",
    "        coef_distribution_criterion (str, optional): criterion to weight these objects: \n",
    "        \"uniform\" weighting, by \"similarity\" or by \"dissimilarity\". Defaults to \"uniform\".\n",
    "        variant (str, optional): variant for the coefficient distribution criterion: \"standard deviation\" (or \"sd\"),\n",
    "        \"cross entropy\" (or \"cross\") or \"total difference\" (or \"Gini index\" or \"Gini\"). Necessary for groups dissimilarity. Defaults to \"sd\".        \n",
    "        selection_mode (str, optional): number of representatives in each class: \"one\", the top weighted (\"top\") or \"all\". Defaults to \"one\".\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model:ground_model, number_groups:int=3, coef_owners=\"UEs\", coef_distribution_criterion=\"uniform\", variant=None, selection_mode=\"one\"): \n",
    "        \n",
    "        # Get ready to use the entered parameters\n",
    "        if coef_owners == None or coef_owners.upper() in [\"UES\", \"UE\"] : coef_owners = \"UEs\"\n",
    "        elif coef_owners.upper() in [\"GROUP\", \"GROUPS\"]: coef_owners = \"groups\"\n",
    "        else:\n",
    "            print(f'The definition of the abstract model is broken. Cause: objects to weights \"{coef_owners}\"' + \n",
    "                  'has unexpected value. Correct values: \"UEs\" and \"groups\".')\n",
    "            return\n",
    "        \n",
    "        if coef_distribution_criterion == None or \"UNIF\" in coef_distribution_criterion.upper(): \n",
    "            coef_distribution_criterion = \"uniform\"\n",
    "        elif \"DIS\" in coef_distribution_criterion.upper(): coef_distribution_criterion = \"dissimilarity\"\n",
    "        elif \"SIM\" in coef_distribution_criterion.upper(): coef_distribution_criterion = \"similarity\"\n",
    "        else:\n",
    "            print(f'The definition of the abstract model is broken. Cause: weighting criterion \"{coef_distribution_criterion}' + \n",
    "                  'has unexpected value. Correct values: \"uniform\", \"similarity\" and \"dissimilarity\".')\n",
    "            return\n",
    "        \n",
    "        if selection_mode == None or selection_mode == 1 or selection_mode.upper() in [\"1\", \"ONE\"]: selection_mode = \"one\"\n",
    "        elif \"TOP\" in selection_mode.upper() or \"MOST\" in selection_mode.upper(): selection_mode = \"top\"\n",
    "        elif selection_mode.upper() in [\"ALL\", \"AL\"]: selection_mode = \"all\"\n",
    "        else:\n",
    "            print(f'The definition of the abstract model is broken. Cause: selection mode \"{selection_mode}' + \n",
    "                  'has unexpected value. Correct values: \"one\", \"top\" and \"all\".')\n",
    "            return\n",
    "        \n",
    "        if coef_owners == \"groups\" and coef_distribution_criterion == \"dissimilarity\":\n",
    "            if variant == None or \"ST\" in variant.upper() or \"SD\" in variant.upper(): variant = \"sd\"\n",
    "            elif \"CROS\" in variant.upper(): variant = \"cross\"\n",
    "            elif \"GINI\" in variant.upper() or \"TOTAL\" in variant.upper(): variant = \"gini\"\n",
    "            else:\n",
    "                print(f'The definition of the abstract model is broken. Cause: variant \"{coef_distribution_criterion}' + \n",
    "                    'has unexpected value. Correct values for group dissimilarity: \"standard deviation\", \"cross entropy\" and \"Gini index\".')\n",
    "                return\n",
    "        else: variant = None\n",
    "        \n",
    "        self.model = model\n",
    "        self.number_groups = torch.tensor(number_groups,dtype=int).to(device)\n",
    "        self.coef_owners, self.coef_distribution_criterion, self.selection_mode = coef_owners, coef_distribution_criterion, selection_mode\n",
    "        self.variant = variant\n",
    "        \n",
    "        abstraction_beginning_time = time.time()\n",
    "        self.make_groups_UEs()  # Group the UEs in groups. Result: group_indices_vector and groups_list, number of UEs per group\n",
    "        self.make_abstraction_function()  # Make the abstract states, the vector of indices of class corresponding to each state, and the list of classes (each class is a tensor)\n",
    "        self.make_weights_distribution()  # Built the vector weight_distribution representing the weight distribution\n",
    "        self.make_abstract_problem()  # Build the transition and cost matrices transition_matrix and cost_matrix for the abstract problem\n",
    "        abstraction_end_time = time.time()\n",
    "        self.abstraction_elapse_time = abstraction_end_time - abstraction_beginning_time\n",
    "        \n",
    "        \n",
    "    def make_groups_UEs(self) -> torch.tensor:  # Group the UEs in groups\n",
    "        def grouping(N):\n",
    "            model = self.model\n",
    "            characteristics_vector = model.number_UEs/model.number_RBs*torch.sum(model.CQI_matrix,dim=1) - model.arrival_rates_vector\n",
    "            if N >= model.number_UEs:\n",
    "                if characteristics_vector.unique().size(0) == characteristics_vector.size(0):\n",
    "                    sorted_indices = torch.argsort(characteristics_vector)\n",
    "                    num_elements = characteristics_vector.size(0)\n",
    "                    vector_groups = torch.zeros(num_elements, dtype=torch.long)\n",
    "                    vector_groups[sorted_indices] = torch.arange(num_elements)\n",
    "                    return vector_groups\n",
    "                else:\n",
    "                    return grouping(model.number_UEs.item() - 1)\n",
    "            quantiles = torch.linspace(0, 1, N+1)[1:-1].to(float).to(device)\n",
    "            bounds_characteristics = torch.quantile(characteristics_vector, quantiles)\n",
    "            _, group_indices_vector = torch.searchsorted(bounds_characteristics, characteristics_vector.unsqueeze(1), right=True).squeeze(1).unique(return_inverse=True)\n",
    "            return group_indices_vector\n",
    "        \n",
    "        self.group_indices_vector = grouping(self.number_groups)\n",
    "        self.number_groups = self.group_indices_vector.unique().size(0)\n",
    "        self.range_group_indices = torch.tensor(range(self.number_groups),dtype=int)\n",
    "        self.groups_list = [torch.where(self.group_indices_vector==g)[0] for g in self.range_group_indices]\n",
    "        groups_size_list = [self.groups_list[g].size(0) for g in self.range_group_indices]\n",
    "        self.groups_size_vector = torch.tensor(groups_size_list,dtype=int).to(device)\n",
    "    \n",
    "    def make_abstraction_function(self):  # Make the matrix of abstract states (states_matrix), the vector of indices of class corresponding to each state(states_vector), \n",
    "        # and the list of classes (classes_list: each class is a tensor)\n",
    "        model = self.model\n",
    "        \n",
    "        # Build the abstract states\n",
    "        max_size_groups = torch.zeros([self.number_groups],dtype=int).to(device)\n",
    "        for g in self.range_group_indices: max_size_groups[g] = model.max_size * self.groups_list[g].size(0)\n",
    "        states = itertools.product(*[range(size+1) for size in max_size_groups])\n",
    "        self.states_matrix = torch.tensor(list(states)).to(device)\n",
    "        self.number_states = self.states_matrix.size(0)\n",
    "        \n",
    "        # Build the abstract function as a vector called states_vector. states_vector[gs_idx] is the index \n",
    "        # of the abstract state corresponding to ground state of index gs_idx\n",
    "        self.states_vector = torch.zeros([model.number_states],dtype=int)\n",
    "        for gs_idx in model.range_state_indices:\n",
    "            print(f\"Getting the abstraction function.  Ground state {gs_idx+2} \" + \n",
    "                  f\"/ {model.number_states.item()+1}  ({(gs_idx+2)/(model.number_states+1).item():.0%})\", end=\"\\r\")\n",
    "            ground_state = model.states_matrix[gs_idx]\n",
    "            abstract_state = torch.zeros([self.number_groups],dtype=int).to(device)\n",
    "            for g in self.range_group_indices:\n",
    "                abstract_state[g] = ground_state[self.groups_list[g]].sum()\n",
    "            for as_idx, row in enumerate(self.states_matrix):\n",
    "                if torch.all(row == abstract_state):\n",
    "                    self.states_vector[gs_idx] = as_idx\n",
    "                    break\n",
    "        print(\" \"*100+\"\\r\",end=\"\\r\")\n",
    "        \n",
    "        # Build the list of classes. classes_list[c_idx] is the class (vector of ground state indices) of ground states \n",
    "        # whom abstract state is of index s_idx\n",
    "        self.range_class_indices = torch.tensor(range(self.number_states),dtype=int)\n",
    "        self.classes_list = [torch.where(self.states_vector==c_idx)[0] for c_idx in self.range_class_indices]\n",
    "    \n",
    "    \n",
    "    def make_weights_distribution(self):  # Built the vector representing the weight distribution\n",
    "        def selection_fn(weight_distribution:torch.tensor) -> torch.tensor:  # Return a final weight distribution \n",
    "            # corresponding to the selection mode\n",
    "            if self.selection_mode == \"all\": return weight_distribution\n",
    "            m = self.model\n",
    "            final_weights_vector = torch.zeros(m.number_states,dtype=float).to(device)\n",
    "            for c_idx in range(len(self.classes_list)): \n",
    "                states = self.classes_list[c_idx].to(device)  # Indices of the states of the current class\n",
    "                local_weights = weight_distribution[states]  # Vector of weights of these states\n",
    "                max_weight = local_weights.max()  # Maximum value of the local weights\n",
    "                top_states_positions = torch.nonzero(local_weights==max_weight).squeeze()  # Local positions within the current class of the states with maximum weight value\n",
    "                if top_states_positions.dim()==0:  # If exactly one state in the class has the local maximum weight value\n",
    "                    for s_idx in states:\n",
    "                        final_weights_vector[s_idx] = (1 if weight_distribution[s_idx]==max_weight else 0)\n",
    "                else:\n",
    "                    top_states = states[top_states_positions]  # Global indices of the states with the maximum local weight value\n",
    "                    num_top_states = top_states.size(0)\n",
    "                    if self.selection_mode == \"top\":\n",
    "                        for s_idx in states: \n",
    "                            final_weights_vector[s_idx] = (1/num_top_states if s_idx in top_states else 0)\n",
    "                    else:\n",
    "                        random_position_in_tops = torch.randint(0, num_top_states, (1,))\n",
    "                        random_top_idx = top_states[random_position_in_tops]\n",
    "                        for s_idx in states:\n",
    "                            final_weights_vector[s_idx] = (1 if random_top_idx==s_idx else 0)\n",
    "                states_and_weights = torch.stack((states, final_weights_vector[states]), dim=0)\n",
    "                # print(f\"c_{c_idx} ≡ {self.states_matrix[c_idx].cpu().numpy()}\\n{states_and_weights.cpu().numpy()}\\n\")\n",
    "            return final_weights_vector\n",
    "        \n",
    "        def weight_fn(distribution:torch.tensor) -> torch.tensor:  # Return a weight distribution any distribution of positive numbers on the states\n",
    "            m = self.model\n",
    "            state_weights_vector = torch.zeros(m.number_states,dtype=float).to(device)\n",
    "            for c_idx in range(len(self.classes_list)): \n",
    "                class_states = self.classes_list[c_idx]\n",
    "                class_weight = distribution[class_states].sum()\n",
    "                if class_weight == 0:\n",
    "                    for s_idx in class_states: state_weights_vector[s_idx] = 1\n",
    "                else:\n",
    "                    for s_idx in class_states: state_weights_vector[s_idx] = distribution[s_idx]/class_weight\n",
    "            return state_weights_vector\n",
    "        \n",
    "        def preweight_fn() -> torch.tensor:  # Distribute numbers on states according to the weights of UEs or groups\n",
    "            m = self.model\n",
    "            state_weights_vector = torch.zeros(m.number_states,dtype=float).to(device)\n",
    "            for s_idx in m.range_state_indices: \n",
    "                coefs_vector = coef_fn(s_idx)\n",
    "                state_weights_vector[s_idx] = coefs_vector.sum()\n",
    "            return state_weights_vector\n",
    "        \n",
    "        def coef_fn(state_idx:int) -> torch.tensor:  # Make a coefficient distribution on UEs or groups according to the state of index state_idx\n",
    "            state = self.model.states_matrix[state_idx]\n",
    "            criterion, coef_owners, variant = self.coef_distribution_criterion, self.coef_owners, self.variant\n",
    "            \n",
    "            # The case of uniform distribution is the most simple: all queues or groups have the same coefficient.\n",
    "            if criterion == \"uniform\":\n",
    "                return (torch.ones([self.model.number_UEs],dtype=float).to(device) \n",
    "                        if coef_owners==\"UEs\" \n",
    "                        else torch.ones([self.number_groups],dtype=float).to(device))  # else means \"groups\"\n",
    "            \n",
    "            # From this point on, the criterion is either \"similarity\" or \"dissimilarity\".\n",
    "            abstract_state_idx = self.states_vector[state_idx]  # Everything relies on the current abstract state.\n",
    "            abstract_state = self.states_matrix[abstract_state_idx]\n",
    "            \n",
    "            # The criterion is either \"similarity\" or \"dissimilarity\", and the owners of the weights are the UEs:\n",
    "            if coef_owners == \"UEs\":\n",
    "                group_means_vector = abstract_state / self.groups_size_vector  # Average number of bits in each group\n",
    "                deviations_vector = torch.zeros([self.model.number_UEs],dtype=float).to(device)  # Difference between the number of bits in each buffer and the corresponding group. Init value.\n",
    "                for ue in self.model.range_UE_indices:\n",
    "                    g_idx = self.group_indices_vector[ue]  # Group of the UE of index ue\n",
    "                    deviations_vector[ue] = torch.abs(state[ue] - group_means_vector[g_idx])\n",
    "                return (torch.exp(-deviations_vector) if criterion==\"similarity\" else deviations_vector)  # else means \"dissimilarity\"\n",
    "            \n",
    "            # From this point on, the criterion is either \"similarity\" or \"dissimilarity\", and the owners of the weights are the groups\n",
    "            coefs_vector = torch.zeros([self.number_groups],dtype=float).to(device)  # For the vector of coefficients to return\n",
    "            if criterion == \"similarity\":  # The criterion is \"similarity\" and the owners of the weights are the groups\n",
    "                for g_idx in self.range_group_indices:\n",
    "                    UEs_vector = torch.where(self.group_indices_vector==g_idx)[0]\n",
    "                    state_restriction = state[UEs_vector]  # Sub-vector of the ground state corresponding to the ground state of index g_Idx\n",
    "                    num_UEs = self.groups_size_vector[g_idx]  # Number of UE buffers in this group\n",
    "                    num_bits = abstract_state[g_idx]  # Total number of bits in this group\n",
    "                    redistribution = torch.full((num_UEs,),num_bits).to(device)  # Assign this total to each UE. The average sounds better, but the total is easier and returns the same cosine\n",
    "                    coefs_vector[g_idx] = F.cosine_similarity(state_restriction.to(float),redistribution,dim=0)\n",
    "                return coefs_vector\n",
    "            \n",
    "            # From this point on, the criterion is \"dissimilarity\", and the owners of the weights are the groups\n",
    "            if variant == \"sd\":  # The criterion is \"dissimilarity\", and the groups should be weighted according to the standard deviation of the bits distribution in each of them\n",
    "                for g_idx in self.range_group_indices:\n",
    "                    num_bits = abstract_state[g_idx]  # Total number of bits in this group\n",
    "                    if num_bits == 0: coefs_vector[g_idx] = 1\n",
    "                    else:\n",
    "                        num_UEs = self.groups_size_vector[g_idx]  # Number of UE buffers in this group\n",
    "                        average_num_bits = num_bits / num_UEs\n",
    "                        redistribution = torch.full((num_UEs,),average_num_bits).to(device)  # Redistribute the bits of the group equally to its UE-members\n",
    "                        UEs_vector = torch.where(self.group_indices_vector==g_idx)[0]\n",
    "                        state_restriction = state[UEs_vector]  # Sub-vector of the ground state corresponding to the ground state of index g_Idx\n",
    "                        square_deviations_vector = (state_restriction - redistribution)**2\n",
    "                        variance = math.sqrt(torch.sum(square_deviations_vector))  # Variance of the bits distribution in the group\n",
    "                        coefs_vector[g_idx] = variance / num_bits  # Coefficient of the group\n",
    "                return coefs_vector\n",
    "            \n",
    "            # From this point on, the criterion is \"dissimilarity\", and the groups should be weighted according to either the cross entropy or the Gini coefficient of the bits distribution in each of them\n",
    "            if variant == \"cross\":  # The criterion is \"dissimilarity\", and the groups should be weighted according to the cross entropy of the bits distribution in each of them\n",
    "                for g_idx in self.range_group_indices:\n",
    "                    # states_idx_vector = torch.where(self.group_indices_vector==g_idx)[0]\n",
    "                    group_size = self.groups_size_vector[g_idx].item()\n",
    "                    num_bits = abstract_state[g_idx]\n",
    "                    entropy = math.log(group_size)*num_bits\n",
    "                    coefs_vector[g_idx] = entropy\n",
    "                return coefs_vector\n",
    "            \n",
    "            # Here, the criterion is \"dissimilarity\", and the groups should be weighted according the Gini coefficient of the bits distribution in each of them\n",
    "            for g_idx in self.range_group_indices:\n",
    "                if abstract_state[g_idx] != 0:\n",
    "                    UEs_vector = torch.where(self.group_indices_vector==g_idx)[0]  # UEs in the current group\n",
    "                    sum_dif = torch.tensor([0],dtype=float).to(device)\n",
    "                    for i, j in itertools.product(UEs_vector, repeat=2):\n",
    "                        sum_dif = sum_dif + torch.abs(state[i] - state[j])\n",
    "                    group_size = self.groups_size_vector[g_idx]\n",
    "                    num_bits = abstract_state[g_idx]\n",
    "                    coefs_vector[g_idx] = sum_dif / (two*group_size*num_bits)\n",
    "            return coefs_vector\n",
    "        preweights_distribution = preweight_fn()\n",
    "        weight_distribution = weight_fn(preweights_distribution)\n",
    "        self.weight_distribution = selection_fn(weight_distribution)\n",
    "    \n",
    "    def make_abstract_problem(self) -> None:\n",
    "        m = self.model\n",
    "        NA, NS = m.number_actions, self.number_states\n",
    "        num_steps = NA*NS*NS\n",
    "        transition_matrix = torch.zeros([NA,NS,NS],dtype=float).to(device)\n",
    "        cost_matrix = torch.zeros([NA,NS],dtype=float).to(device)\n",
    "        step = zero\n",
    "        variant = (\"--\" if self.variant==None else self.variant)\n",
    "        abstraction = [self.number_groups, self.coef_owners, self.coef_distribution_criterion, variant, self.selection_mode]\n",
    "        for a_idx, c_idx1, c_idx2 in itertools.product(m.range_action_indices, self.range_class_indices, self.range_class_indices):\n",
    "            step = step + one\n",
    "            print(f\"Abstraction {abstraction} ► Fetching the abstract transition and cost matrices ..... step {step.to(int).item()}/{num_steps.item()} ({(step/num_steps).item():.0%})\", end=\"\\r\")\n",
    "            transition_matrix[a_idx,c_idx1,c_idx2] = zero\n",
    "            cost_matrix[a_idx,c_idx1] = zero\n",
    "            class1, class2 = self.classes_list[c_idx1], self.classes_list[c_idx2]\n",
    "            action = m.actions_matrix[a_idx]\n",
    "            for s_idx1 in class1:\n",
    "                state1 = m.states_matrix[s_idx1]\n",
    "                probability = zero\n",
    "                for s_idx2 in class2: \n",
    "                    state2 = m.states_matrix[s_idx2]\n",
    "                    probability = probability + m.transition_probability_fn(state1, action, state2)\n",
    "                weight = self.weight_distribution[s_idx1]\n",
    "                transition_matrix[a_idx,c_idx1,c_idx2] = transition_matrix[a_idx,c_idx1,c_idx2] + weight*probability\n",
    "                cost = m.cost_fn(state1,action)\n",
    "                cost_matrix[a_idx,c_idx1] = cost_matrix[a_idx,c_idx1] + weight*cost\n",
    "        self.transition_matrix, self.cost_matrix = transition_matrix, cost_matrix\n",
    "        print(\" \"*150, end=\"\\r\")\n",
    "        \n",
    "    def resolution(self, discount_factor=None, precision=None) -> None:\n",
    "        \n",
    "        # Find the solution of the abstract MDP\n",
    "        m = self.model\n",
    "        discount_factor = (m.discount_factor if discount_factor==None else discount_factor)\n",
    "        discount_factor = torch.tensor([discount_factor],dtype=float).to(device)\n",
    "        error_factor = discount_factor / (one-discount_factor)\n",
    "        precision = (m.precision if precision==None else precision)\n",
    "        resolution_beginning_time = time.time()\n",
    "        variant = (\"--\" if self.variant==None else self.variant)\n",
    "        abstraction = [self.number_groups, self.coef_owners, self.coef_distribution_criterion, variant, self.selection_mode]\n",
    "        num_states, num_actions = self.number_states, m.number_actions\n",
    "        old_value, new_value = torch.zeros([num_states],dtype=float).to(device), torch.zeros([num_states],dtype=float).to(device)\n",
    "        error = \"#NA\"\n",
    "        policy = torch.zeros([num_states],dtype=int).to(device)\n",
    "        while True:\n",
    "            for c_idx in self.range_class_indices:  # Index of the current state. For each state, get in the new value function the optimal update of the old value function\n",
    "                print(f\"Abstraction {abstraction} ► Solving ..... Current error = {error};  current class number = {c_idx.item()}\", end=\"\\r\")\n",
    "                Q = torch.zeros([num_actions],dtype=float).to(device)  # Cost of applying each action\n",
    "                for a in m.range_action_indices:\n",
    "                    Q[a] = self.cost_matrix[a,c_idx] + discount_factor*torch.dot(self.transition_matrix[a,c_idx],old_value)\n",
    "                new_value[c_idx] = torch.min(Q)  # Minimum possible cost in the current state\n",
    "                policy[c_idx] = torch.argmin(Q)  # Action that causes this minimum cost\n",
    "            differences_vector = new_value - old_value\n",
    "            difference_max, difference_min = torch.max(differences_vector), torch.min(differences_vector)\n",
    "            difference_scope = difference_max - difference_min\n",
    "            error = (error_factor * difference_scope).item()  # Bound of the error of taking new_value as the optimal value function\n",
    "            if error <= precision: break\n",
    "            else: old_value = new_value.clone()\n",
    "        print(\" \"*250, end=\"\\r\")\n",
    "        self.abstract_solution = torch.stack([policy, new_value])\n",
    "        resolution_end_time = time.time()\n",
    "        self.resolution_elapse_time = resolution_end_time - resolution_beginning_time\n",
    "        self.precision = error\n",
    "        \n",
    "        # Extrapolate the abstract solution to find the solution of the ground queuing problem\n",
    "        extrapolation_beginning_time = time.time()\n",
    "        solution = torch.zeros([2,m.number_states],dtype=float).to(device)\n",
    "        for s_idx in m.range_state_indices:\n",
    "            c_idx = self.states_vector[s_idx]\n",
    "            solution[:,s_idx] = self.abstract_solution[:,c_idx]\n",
    "        self.solution = solution\n",
    "        extrapolation_end_time = time.time()\n",
    "        self.extrapolation_elapse_time = extrapolation_end_time - extrapolation_beginning_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class abstractions_comparison:\n",
    "    \n",
    "    def __init__(self, gm:ground_model) -> None:\n",
    "        self.gm = gm\n",
    "        self.get_numbers_groups_list()\n",
    "        self.coefs_owners_list = [\"UEs\", \"groups\"]\n",
    "        self.coefs_distribution_criteria_list = [\"uniform\", \"sim\", \"dissim\"]\n",
    "        self.variants_list = [\"sd\", \"cross\", \"gini\"]\n",
    "        self.selection_modes_list = [\"one\", \"top\", \"all\"]\n",
    "        self.path = os.path.join(gm.directory, \"Abstractions_comparison.csv\")\n",
    "        self.headers = [\"ID\", \"n_groups\", \"coef_owners\", \"coef_criterion\", \"criterion_variant\", \"select_mode\",\n",
    "                        \"max_diff_values\", \"avrg_diff_values\", \"max_diff_actions\", \"avrg_diff_actions\",\n",
    "                        \"abstraction_time\", \"resolution_time\", \"extrapolation_time\"]\n",
    "    \n",
    "    def get_numbers_groups_list(self) -> torch.tensor:  # Return the possible numbers of groups\n",
    "        def number_groups_fn(N):\n",
    "            model = self.gm\n",
    "            characteristics_vector = model.number_UEs/model.number_RBs*torch.sum(model.CQI_matrix,dim=1) - model.arrival_rates_vector\n",
    "            if N >= model.number_UEs:\n",
    "                if characteristics_vector.unique().size(0) == characteristics_vector.size(0):\n",
    "                    sorted_indices = torch.argsort(characteristics_vector)\n",
    "                    num_elements = characteristics_vector.size(0)\n",
    "                    vector_groups = torch.zeros(num_elements, dtype=torch.long)\n",
    "                    vector_groups[sorted_indices] = torch.arange(num_elements)\n",
    "                    return vector_groups\n",
    "                else:\n",
    "                    return number_groups_fn(model.number_UEs.item() - 1)\n",
    "            quantiles = torch.linspace(0, 1, N+1)[1:-1].to(float).to(device)\n",
    "            bounds_characteristics = torch.quantile(characteristics_vector, quantiles)\n",
    "            _, group_indices_vector = torch.searchsorted(bounds_characteristics, characteristics_vector.unsqueeze(1), right=True).squeeze(1).unique(return_inverse=True)\n",
    "            return group_indices_vector.unique().size(0)\n",
    "        \n",
    "        numbers_groups_list = []\n",
    "        for target_number_groups in range(self.gm.number_UEs):\n",
    "            number_groups = number_groups_fn(target_number_groups)\n",
    "            if not number_groups in numbers_groups_list: numbers_groups_list.append(number_groups)\n",
    "        self.numbers_groups_list = numbers_groups_list\n",
    "        \n",
    "    def launch(self):\n",
    "        ID = 0\n",
    "        total = 24*len(self.numbers_groups_list)\n",
    "        gm = self.gm\n",
    "        numbers_groups = self.numbers_groups_list\n",
    "        owners = self.coefs_owners_list\n",
    "        criteria = self.coefs_distribution_criteria_list\n",
    "        variants = self.variants_list\n",
    "        modes = self.selection_modes_list\n",
    "        with open(self.path, mode=\"w\", newline=\"\") as destination:\n",
    "            writer = csv.writer(destination)\n",
    "            writer.writerow(self.headers)\n",
    "            \n",
    "            for ng,owner,criterion,mode in itertools.product(numbers_groups,owners,criteria,modes):\n",
    "                if owner==\"groups\" or criterion==\"dissim\":\n",
    "                    for variant in variants:\n",
    "                        ID += 1\n",
    "                        abstraction = [\"groups=\"+str(ng), \"owners=\"+str(owner), \"criterion=\"+str(criterion), \"variant=\"+str(variant), \"selectionMode=\"+str(mode)]\n",
    "                        print(f\"Getting the performance of abstraction {abstraction}  =  abstraction {ID}/{total} ({ID/total:.0%})\")\n",
    "                        am = abstract_model(model=gm, number_groups=ng, coef_owners=owner, coef_distribution_criterion=criterion, variant=variant, selection_mode=mode)\n",
    "                        am.resolution()\n",
    "                        differences = torch.abs(gm.solution - am.solution)\n",
    "                        max_diff_values = torch.max(differences[1]).item()\n",
    "                        average_diff_values = torch.mean(differences[1]).item()\n",
    "                        max_diff_actions = torch.max(differences[0]).to(int).item()\n",
    "                        average_diff_actions = torch.mean(differences[0]).item()\n",
    "                        row = [ID, ng, owner, criterion, variant, mode,\n",
    "                               max_diff_values, average_diff_values, max_diff_actions, average_diff_actions,\n",
    "                               am.abstraction_elapse_time, am.resolution_elapse_time, am.extrapolation_elapse_time]\n",
    "                        writer.writerow(row)\n",
    "                else:\n",
    "                    ID += 1\n",
    "                    abstraction = [\"groups=\"+str(ng), \"owners=\"+str(owner), \"criterion=\"+str(criterion), \"variant=--\", \"selectionMode=\"+str(mode)]\n",
    "                    print(f\"Getting the performance of abstraction {abstraction}  =  abstraction {ID}/{total} ({ID/total:.0%})\")\n",
    "                    am = abstract_model(model=gm, number_groups=ng, coef_owners=owner, coef_distribution_criterion=criterion, selection_mode=mode)\n",
    "                    am.resolution()\n",
    "                    differences = torch.abs(gm.solution - am.solution)\n",
    "                    max_diff_values = torch.max(differences[1]).item()\n",
    "                    average_diff_values = torch.mean(differences[1]).item()\n",
    "                    max_diff_actions = torch.max(differences[0]).to(int).item()\n",
    "                    average_diff_actions = torch.mean(differences[0]).item()\n",
    "                    row = [ID, ng, owner, criterion, \"--\", mode,\n",
    "                            max_diff_values, average_diff_values, max_diff_actions, average_diff_actions,\n",
    "                            am.abstraction_elapse_time, am.resolution_elapse_time, am.extrapolation_elapse_time]\n",
    "                    writer.writerow(row)\n",
    "    \n",
    "    def view(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 id=Tests>TESTS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3>Ground Model for the Queuing Problem</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the arrival rate for each UE.\n",
      "Arrival rate for UE 0: \n",
      "Arrival rate for UE 1: \n",
      "Arrival rate for UE 2: \n"
     ]
    }
   ],
   "source": [
    "m = ground_model(2,3,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3>Cost and Transition Functions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "With action a_0 = [0 0]\n",
      "\n",
      "Step 27/243 (11%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                             \n",
      "\n",
      "With action a_1 = [0 1]\n",
      "\n",
      "Step 54/243 (22%):  Last sum of proba = 0.9999999999999999,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                               \n",
      "\n",
      "With action a_2 = [0 2]\n",
      "\n",
      "Step 81/243 (33%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                              \n",
      "\n",
      "With action a_3 = [1 0]\n",
      "\n",
      "Step 108/243 (44%):  Last sum of proba = 0.9999999999999999,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                               \n",
      "\n",
      "With action a_4 = [1 1]\n",
      "\n",
      "Step 135/243 (56%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                              \n",
      "\n",
      "With action a_5 = [1 2]\n",
      "\n",
      "Step 162/243 (67%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                              \n",
      "\n",
      "With action a_6 = [2 0]\n",
      "\n",
      "Step 189/243 (78%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                              \n",
      "\n",
      "With action a_7 = [2 1]\n",
      "\n",
      "Step 216/243 (89%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                              \n",
      "\n",
      "With action a_8 = [2 2]\n",
      "\n",
      "Step 243/243 (100%):  Last sum of proba = 1.0,  Max error = 2.220446049250313e-16.     Progress in the current step: 100%                                             \n",
      "Max error = 2.220446049250313e-16\n"
     ]
    }
   ],
   "source": [
    "# TEST FOR TRANSITION PROBABILITIES\n",
    "\n",
    "max_diff = \"NA\"\n",
    "SN = \"NA\"\n",
    "num_steps = (m.number_actions * m.number_states).item()\n",
    "step = 0\n",
    "num_states = m.number_states.item()\n",
    "for ai in range(m.number_actions):\n",
    "    AT = m.actions_matrix[ai]\n",
    "    AN = AT.cpu().numpy()\n",
    "    print(f\"\\n\\nWith action a_{ai} = {AN}\\n\")\n",
    "    for si1 in range(m.number_states):\n",
    "        step += 1\n",
    "        S1T = m.states_matrix[si1]\n",
    "        S1N = S1T.cpu().numpy()\n",
    "        S = torch.tensor([0]).to(device)\n",
    "        state = 0\n",
    "        for si2 in range(m.number_states):\n",
    "            state += 1\n",
    "            S2T = m.states_matrix[si2]\n",
    "            PT = m.transition_probability_fn(S1T,AT,S2T)\n",
    "            S = S + PT\n",
    "            S2N, PN = S2T.cpu().numpy(), PT.item()\n",
    "            # print(f\"a_{ai}:      {S1N} --->  {S2N}:    P = {PN}\")\n",
    "            print(f\"Step {step}/{num_steps} ({step/num_steps:.0%}):  Last sum of proba = {SN},  Max error = {max_diff}.     Progress in the current step: {state/num_states:.0%}                               \", end=\"\\r\")\n",
    "        SN = S.item()\n",
    "        # print(f\"\\n                  Sum of probabilities = {SN}\\n\\n\")\n",
    "        max_diff = (abs(SN-1) if max_diff == \"NA\" else max((max_diff, abs(SN-1))))\n",
    "print(f\"\\nMax error = {max_diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action [0 0]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 0]  in state [0 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 0]  in state [0 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 0]  in state [0 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 0]  in state [0 1 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 0]  in state [0 1 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [0 0]  in state [0 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 0]  in state [0 2 1]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [0 0]  in state [0 2 2]      --->      Rest = [0 2 2]  and Cost = 4.0\n",
      "Action [0 0]  in state [1 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 0]  in state [1 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 0]  in state [1 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 0]  in state [1 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 0]  in state [1 1 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 0]  in state [1 1 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [0 0]  in state [1 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 0]  in state [1 2 1]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [0 0]  in state [1 2 2]      --->      Rest = [0 2 2]  and Cost = 4.0\n",
      "Action [0 0]  in state [2 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 0]  in state [2 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 0]  in state [2 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 0]  in state [2 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 0]  in state [2 1 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 0]  in state [2 1 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [0 0]  in state [2 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 0]  in state [2 2 1]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [0 0]  in state [2 2 2]      --->      Rest = [0 2 2]  and Cost = 4.0\n",
      "Action [0 1]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 1]  in state [0 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 1]  in state [0 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 1]  in state [0 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 1]  in state [0 1 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 1]  in state [0 1 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 1]  in state [0 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 1]  in state [0 2 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 1]  in state [0 2 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [0 1]  in state [1 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 1]  in state [1 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 1]  in state [1 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 1]  in state [1 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 1]  in state [1 1 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 1]  in state [1 1 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [0 1]  in state [1 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 1]  in state [1 2 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 1]  in state [1 2 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [0 1]  in state [2 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [0 1]  in state [2 0 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [0 1]  in state [2 0 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [0 1]  in state [2 1 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [0 1]  in state [2 1 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [0 1]  in state [2 1 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [0 1]  in state [2 2 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [0 1]  in state [2 2 1]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [0 1]  in state [2 2 2]      --->      Rest = [1 1 2]  and Cost = 4.0\n",
      "Action [0 2]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 2]  in state [0 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 2]  in state [0 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 2]  in state [0 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 2]  in state [0 1 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 2]  in state [0 1 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 2]  in state [0 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [0 2 1]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [0 2 2]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [0 2]  in state [1 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 2]  in state [1 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [0 2]  in state [1 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [0 2]  in state [1 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 2]  in state [1 1 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [0 2]  in state [1 1 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [0 2]  in state [1 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [1 2 1]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [1 2 2]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [0 2]  in state [2 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [0 2]  in state [2 0 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [0 2]  in state [2 0 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [0 2]  in state [2 1 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [2 1 1]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [0 2]  in state [2 1 2]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [0 2]  in state [2 2 0]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [0 2]  in state [2 2 1]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [0 2]  in state [2 2 2]      --->      Rest = [1 2 1]  and Cost = 4.0\n",
      "Action [1 0]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 0]  in state [0 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 0]  in state [0 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 0]  in state [0 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 0]  in state [0 1 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 0]  in state [0 1 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 0]  in state [0 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [1 0]  in state [0 2 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [1 0]  in state [0 2 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [1 0]  in state [1 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 0]  in state [1 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 0]  in state [1 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 0]  in state [1 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 0]  in state [1 1 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 0]  in state [1 1 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 0]  in state [1 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [1 0]  in state [1 2 1]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [1 0]  in state [1 2 2]      --->      Rest = [0 1 2]  and Cost = 3.0\n",
      "Action [1 0]  in state [2 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 0]  in state [2 0 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 0]  in state [2 0 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [1 0]  in state [2 1 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 0]  in state [2 1 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 0]  in state [2 1 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [1 0]  in state [2 2 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [1 0]  in state [2 2 1]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [1 0]  in state [2 2 2]      --->      Rest = [1 1 2]  and Cost = 4.0\n",
      "Action [1 1]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 1]  in state [0 0 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 1]  in state [0 0 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 1]  in state [0 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 1]  in state [0 1 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 1]  in state [0 1 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 1]  in state [0 2 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 1]  in state [0 2 1]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 1]  in state [0 2 2]      --->      Rest = [0 0 2]  and Cost = 1.9999999999999998\n",
      "Action [1 1]  in state [1 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 1]  in state [1 0 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [1 0 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [1 1]  in state [1 1 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 1]  in state [1 1 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [1 1 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [1 1]  in state [1 2 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 1]  in state [1 2 1]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [1 2 2]      --->      Rest = [1 0 2]  and Cost = 3.0000000000000004\n",
      "Action [1 1]  in state [2 0 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [2 0 1]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [1 1]  in state [2 0 2]      --->      Rest = [2 0 2]  and Cost = 4.0\n",
      "Action [1 1]  in state [2 1 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [2 1 1]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [1 1]  in state [2 1 2]      --->      Rest = [2 0 2]  and Cost = 4.0\n",
      "Action [1 1]  in state [2 2 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 1]  in state [2 2 1]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [1 1]  in state [2 2 2]      --->      Rest = [2 0 2]  and Cost = 4.0\n",
      "Action [1 2]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 2]  in state [0 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 2]  in state [0 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 2]  in state [0 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 2]  in state [0 1 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [1 2]  in state [0 1 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [1 2]  in state [0 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [1 2]  in state [0 2 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [1 2]  in state [0 2 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [1 2]  in state [1 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 2]  in state [1 0 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 2]  in state [1 0 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [1 1 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 2]  in state [1 1 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [1 2]  in state [1 1 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [1 2 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [1 2]  in state [1 2 1]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [1 2]  in state [1 2 2]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [1 2]  in state [2 0 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [2 0 1]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [2 0 2]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [1 2]  in state [2 1 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [2 1 1]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [1 2]  in state [2 1 2]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [1 2]  in state [2 2 0]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [1 2]  in state [2 2 1]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [1 2]  in state [2 2 2]      --->      Rest = [2 1 1]  and Cost = 4.0\n",
      "Action [2 0]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 0]  in state [0 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 0]  in state [0 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [2 0]  in state [0 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 0]  in state [0 1 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 0]  in state [0 1 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [2 0]  in state [0 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [0 2 1]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [0 2 2]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [2 0]  in state [1 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 0]  in state [1 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 0]  in state [1 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [2 0]  in state [1 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 0]  in state [1 1 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 0]  in state [1 1 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [2 0]  in state [1 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [1 2 1]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [1 2 2]      --->      Rest = [0 2 1]  and Cost = 3.0\n",
      "Action [2 0]  in state [2 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 0]  in state [2 0 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 0]  in state [2 0 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [2 0]  in state [2 1 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [2 1 1]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 0]  in state [2 1 2]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [2 0]  in state [2 2 0]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [2 0]  in state [2 2 1]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [2 0]  in state [2 2 2]      --->      Rest = [1 2 1]  and Cost = 4.0\n",
      "Action [2 1]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 1]  in state [0 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 1]  in state [0 0 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [2 1]  in state [0 1 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 1]  in state [0 1 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 1]  in state [0 1 2]      --->      Rest = [0 0 1]  and Cost = 1.0\n",
      "Action [2 1]  in state [0 2 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 1]  in state [0 2 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 1]  in state [0 2 2]      --->      Rest = [0 1 1]  and Cost = 2.0\n",
      "Action [2 1]  in state [1 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 1]  in state [1 0 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 1]  in state [1 0 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [1 1 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 1]  in state [1 1 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 1]  in state [1 1 2]      --->      Rest = [1 0 1]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [1 2 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 1]  in state [1 2 1]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 1]  in state [1 2 2]      --->      Rest = [1 1 1]  and Cost = 3.0\n",
      "Action [2 1]  in state [2 0 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [2 0 1]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [2 0 2]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [2 1]  in state [2 1 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [2 1 1]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 1]  in state [2 1 2]      --->      Rest = [2 0 1]  and Cost = 3.0\n",
      "Action [2 1]  in state [2 2 0]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [2 1]  in state [2 2 1]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [2 1]  in state [2 2 2]      --->      Rest = [2 1 1]  and Cost = 4.0\n",
      "Action [2 2]  in state [0 0 0]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 2]  in state [0 0 1]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 2]  in state [0 0 2]      --->      Rest = [0 0 0]  and Cost = 0.0\n",
      "Action [2 2]  in state [0 1 0]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 2]  in state [0 1 1]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 2]  in state [0 1 2]      --->      Rest = [0 1 0]  and Cost = 0.9999999999999999\n",
      "Action [2 2]  in state [0 2 0]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [0 2 1]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [0 2 2]      --->      Rest = [0 2 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [1 0 0]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 2]  in state [1 0 1]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 2]  in state [1 0 2]      --->      Rest = [1 0 0]  and Cost = 1.0\n",
      "Action [2 2]  in state [1 1 0]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [1 1 1]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [1 1 2]      --->      Rest = [1 1 0]  and Cost = 2.0\n",
      "Action [2 2]  in state [1 2 0]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [1 2 1]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [1 2 2]      --->      Rest = [1 2 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [2 0 0]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 2]  in state [2 0 1]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 2]  in state [2 0 2]      --->      Rest = [2 0 0]  and Cost = 2.0000000000000004\n",
      "Action [2 2]  in state [2 1 0]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [2 1 1]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [2 1 2]      --->      Rest = [2 1 0]  and Cost = 3.0\n",
      "Action [2 2]  in state [2 2 0]      --->      Rest = [2 2 0]  and Cost = 4.0\n",
      "Action [2 2]  in state [2 2 1]      --->      Rest = [2 2 0]  and Cost = 4.0\n",
      "Action [2 2]  in state [2 2 2]      --->      Rest = [2 2 0]  and Cost = 4.0\n",
      "\n",
      "The correlation coefficient between the cost and the sum of the rest in UE buffers is 1.0\n"
     ]
    }
   ],
   "source": [
    "# TEST OF COSTS\n",
    "\n",
    "list_rests = list_costs = []\n",
    "for a,s in product(m.range_action_indices,m.range_state_indices):\n",
    "    action, state = m.actions_matrix[a], m.states_matrix[s]\n",
    "    remainder = m.remainder_fn(state,action)\n",
    "    cost = m.cost_fn(state, action)\n",
    "    list_rests.append(torch.sum(remainder).item())\n",
    "    list_costs.append(cost.item())\n",
    "    print(f\"Action {action.cpu().numpy()}  in state {state.cpu().numpy()}      --->      Rest = {remainder.cpu().numpy()}  and Cost = {cost.item()}\")\n",
    "print(f\"\\nThe correlation coefficient between the cost and the sum of the rest in UE buffers is {np.corrcoef(list_costs,list_rests)[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3>Resolution</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground model resolution.   Updating the value (step 1).  Current error: 0.0;  current state: s_26\r"
     ]
    }
   ],
   "source": [
    "m.resolution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State [0 0 0]  --->   [0 0]\n",
      "State [0 0 1]  --->   [0 2]\n",
      "State [0 0 2]  --->   [2 2]\n",
      "State [0 1 0]  --->   [0 1]\n",
      "State [0 1 1]  --->   [1 2]\n",
      "State [0 1 2]  --->   [2 2]\n",
      "State [0 2 0]  --->   [1 1]\n",
      "State [0 2 1]  --->   [1 2]\n",
      "State [0 2 2]  --->   [2 2]\n",
      "State [1 0 0]  --->   [0 0]\n",
      "State [1 0 1]  --->   [0 2]\n",
      "State [1 0 2]  --->   [2 2]\n",
      "State [1 1 0]  --->   [0 1]\n",
      "State [1 1 1]  --->   [1 2]\n",
      "State [1 1 2]  --->   [2 2]\n",
      "State [1 2 0]  --->   [1 1]\n",
      "State [1 2 1]  --->   [1 2]\n",
      "State [1 2 2]  --->   [2 2]\n",
      "State [2 0 0]  --->   [0 0]\n",
      "State [2 0 1]  --->   [0 2]\n",
      "State [2 0 2]  --->   [2 2]\n",
      "State [2 1 0]  --->   [0 0]\n",
      "State [2 1 1]  --->   [0 2]\n",
      "State [2 1 2]  --->   [0 2]\n",
      "State [2 2 0]  --->   [0 0]\n",
      "State [2 2 1]  --->   [0 2]\n",
      "State [2 2 2]  --->   [0 0]\n"
     ]
    }
   ],
   "source": [
    "for s in m.range_state_indices:\n",
    "    action_number = m.solution[0,s].to(int).item()\n",
    "    state = m.states_matrix[s].cpu().numpy()\n",
    "    action = m.actions_matrix[action_number].cpu().numpy()\n",
    "    print(f\"State {state}  --->   {action}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 2.0000e+00, 8.0000e+00, 1.0000e+00, 5.0000e+00, 8.0000e+00,\n",
       "         4.0000e+00, 5.0000e+00, 5.0000e+00, 0.0000e+00, 2.0000e+00, 8.0000e+00,\n",
       "         1.0000e+00, 5.0000e+00, 8.0000e+00, 4.0000e+00, 5.0000e+00, 5.0000e+00,\n",
       "         0.0000e+00, 2.0000e+00, 8.0000e+00, 1.0000e+00, 2.0000e+00, 8.0000e+00,\n",
       "         0.0000e+00, 2.0000e+00, 1.0000e+00],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
       "         7.2041e-03, 1.0036e+00, 2.0105e+00, 4.6246e-02, 4.6360e-02, 1.0001e+00,\n",
       "         5.7396e-02, 1.0038e+00, 2.0017e+00, 1.0215e+00, 2.0143e+00, 3.0219e+00,\n",
       "         3.0872e-01, 1.0923e+00, 2.0411e+00, 1.2669e+00, 2.1248e+00, 3.0909e+00,\n",
       "         2.3989e+00, 3.3887e+00, 4.4870e+00]], device='cuda:0',\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a_0 = [0 0] in [3 0 0]: rest = [1 0 0],  cost = 1.0\n",
      "a_1 = [0 1] in [3 0 0]: rest = [2 0 0],  cost = 1.9999999999999998\n",
      "a_2 = [0 2] in [3 0 0]: rest = [2 0 0],  cost = 1.9999999999999998\n",
      "a_3 = [1 0] in [3 0 0]: rest = [2 0 0],  cost = 1.9999999999999998\n",
      "a_4 = [1 1] in [3 0 0]: rest = [3 0 0],  cost = 0.0\n",
      "a_5 = [1 2] in [3 0 0]: rest = [3 0 0],  cost = 0.0\n",
      "a_6 = [2 0] in [3 0 0]: rest = [2 0 0],  cost = 1.9999999999999998\n",
      "a_7 = [2 1] in [3 0 0]: rest = [3 0 0],  cost = 0.0\n",
      "a_8 = [2 2] in [3 0 0]: rest = [3 0 0],  cost = 0.0\n"
     ]
    }
   ],
   "source": [
    "state = torch.tensor([3,0,0])\n",
    "for a in m.range_action_indices:\n",
    "    action = m.actions_matrix[a]\n",
    "    cost = m.cost_fn(state,action).item()\n",
    "    rest = m.remainder_fn(state,action).cpu().numpy()\n",
    "    print(f\"a_{a} = {action.cpu().numpy()} in {state.cpu().numpy()}: rest = {rest},  cost = {cost}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Abstract Queuing Model (any)</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                      \r"
     ]
    }
   ],
   "source": [
    "am = abstract_model(m,2,\"ue\", \"dis\", \"cross\", \"all\")\n",
    "# am.number_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                          \r"
     ]
    }
   ],
   "source": [
    "am.resolution(discount_factor=0.7, precision=1e-16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177.45835423469543\n",
      "1.1395964622497559\n",
      "0.0009372234344482422\n",
      "____________________________\n",
      "178.59888792037964\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(am.abstraction_elapse_time)\n",
    "print(am.resolution_elapse_time)\n",
    "print(am.extrapolation_elapse_time)\n",
    "print(\"____________________________\")\n",
    "print(am.abstraction_elapse_time + am.resolution_elapse_time + am.extrapolation_elapse_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract state [0 0]:  total weight = 1.0\n",
      "Abstract state [0 1]:  total weight = 1.0\n",
      "Abstract state [0 2]:  total weight = 1.0\n",
      "Abstract state [0 3]:  total weight = 1.0\n",
      "Abstract state [0 4]:  total weight = 1.0\n",
      "Abstract state [1 0]:  total weight = 1.0\n",
      "Abstract state [1 1]:  total weight = 1.0\n",
      "Abstract state [1 2]:  total weight = 1.0\n",
      "Abstract state [1 3]:  total weight = 1.0\n",
      "Abstract state [1 4]:  total weight = 1.0\n",
      "Abstract state [2 0]:  total weight = 1.0\n",
      "Abstract state [2 1]:  total weight = 1.0\n",
      "Abstract state [2 2]:  total weight = 1.0\n",
      "Abstract state [2 3]:  total weight = 1.0\n",
      "Abstract state [2 4]:  total weight = 1.0\n"
     ]
    }
   ],
   "source": [
    "for c_idx in range(len(am.classes_list)):\n",
    "    states = am.classes_list[c_idx]\n",
    "    abstract_state = am.states_matrix[c_idx].cpu().numpy()\n",
    "    weight = am.weight_distribution[states].sum().item()\n",
    "    print(f\"Abstract state {abstract_state}:  total weight = {weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h2 id=\"Simulations\">SIMULATIONS</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Comparison of Abstract Models Performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ground_model(2,3,2)\n",
    "ac = abstractions_comparison(m)\n",
    "ac.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <h3>Performance of the Best Abstract Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
